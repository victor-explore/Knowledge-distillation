{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Resnet-50 on the Animal dataset and measure the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 90\n",
    "NUM_EPOCHS = 50\n",
    "TRAIN_RESNET = False\n",
    "DISTILL_RESNET = True\n",
    "os.makedirs('ASSN3/models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    classifier_dataset = datasets.ImageFolder(root='data/Animals_data/animals/animals',  # Specify the root directory of the dataset\n",
    "                                              transform=transform)  # Apply the defined transformations to the dataset\n",
    "\n",
    "    train_size = int(0.8 * len(classifier_dataset))\n",
    "    test_size = len(classifier_dataset) - train_size\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    train_dataset, test_dataset = random_split(\n",
    "        classifier_dataset, [train_size, test_size])\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = prepare_datasets()\n",
    "train_loader = DataLoader(train_dataset, batch_size=64,\n",
    "                          num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    top1_correct = 0\n",
    "    top5_correct = 0\n",
    "    total = 0\n",
    "    true_positives = torch.zeros(NUM_CLASSES).to(device)\n",
    "    false_positives = torch.zeros(NUM_CLASSES).to(device)\n",
    "    false_negatives = torch.zeros(NUM_CLASSES).to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.topk(\n",
    "                5, 1, largest=True, sorted=True)\n",
    "            predicted = predicted.t()\n",
    "            top1_correct += (predicted[0] == labels).sum().item()\n",
    "            top5_correct += (predicted ==\n",
    "                             labels.unsqueeze(0)).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                pred = predicted[0][i]\n",
    "                if pred == label:\n",
    "                    true_positives[label] += 1\n",
    "                else:\n",
    "                    false_positives[pred] += 1\n",
    "                    false_negatives[label] += 1\n",
    "\n",
    "    # Calculate precision, recall, and F1 for each class\n",
    "    precision_per_class = true_positives / \\\n",
    "        (true_positives + false_positives + 1e-10)  # Avoid division by zero\n",
    "    recall_per_class = true_positives / \\\n",
    "        (true_positives + false_negatives + 1e-10)\n",
    "\n",
    "    # Average precision and recall over all classes\n",
    "    precision = precision_per_class.mean().item()\n",
    "    recall = recall_per_class.mean().item()\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "\n",
    "    top1_accuracy = 100 * top1_correct / total\n",
    "    top5_accuracy = 100 * top5_correct / total\n",
    "    return top1_accuracy, top5_accuracy, f1\n",
    "\n",
    "\n",
    "def train_classifier(num_epochs):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = resnet50(num_classes = NUM_CLASSES).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    train_losses = []\n",
    "    top1_accuracies = []\n",
    "    top5_accuracies = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in trange(num_epochs, desc=\"Training Progress\"):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()  # Accumulate loss for this epoch\n",
    "\n",
    "        # Validation\n",
    "        top1_accuracy, top5_accuracy, _ = test(model)\n",
    "        top1_accuracies.append(top1_accuracy)\n",
    "        top5_accuracies.append(top5_accuracy)\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        # Store average loss for this epoch\n",
    "        train_losses.append(epoch_loss)\n",
    "        if epoch % 5 == 0:\n",
    "            print(f'Epoch [{\n",
    "                epoch+1}/{num_epochs}] Top-1: {top1_accuracy:.2f}%, Top-5: {top5_accuracy:.2f}%')\n",
    "\n",
    "    print('Finished Training')\n",
    "    plot_metrics(train_losses, top1_accuracies, top5_accuracies)\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_metrics(train_losses, top1_accuracies, top5_accuracies):\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    num_epochs = len(train_losses)\n",
    "    # Plot Training Loss for Each Epoch\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses,\n",
    "             marker='o', color='b', label='Training Loss')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Training Accuracy for Each Epoch\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), top1_accuracies,\n",
    "             marker='o', color='g', label='Top 1 Accuracy')\n",
    "    plt.title('Top 1 Accuracy per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(1, num_epochs + 1), top5_accuracies,\n",
    "             marker='o', color='g', label='Top 5 Accuracy')\n",
    "    plt.title('Top 5 Accuracy per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model_path = \"ASSN3/models/resnet_classifier.pth\"\n",
    "if TRAIN_RESNET:\n",
    "    resnet_classifier = train_classifier(num_epochs=NUM_EPOCHS)\n",
    "    # Save the model\n",
    "    torch.save(resnet_classifier.state_dict(), resnet_model_path)\n",
    "else:\n",
    "    resnet_classifier = resnet50(num_classes=NUM_CLASSES).to(device)\n",
    "    resnet_classifier.load_state_dict(\n",
    "        torch.load(resnet_model_path, weights_only=True))\n",
    "\n",
    "top1_accuracy, top5_accuracy, f1 = test(resnet_classifier)\n",
    "print(f\"Top-1: {top1_accuracy:.2f}%, Top-5: {top5_accuracy:.2f}%, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distill the above resent on a small-sized MLP (using KL distillation loss across logits) and measure the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "TEMPERATURE = 2.0\n",
    "mlp_resnet_model_path = \"ASSN3/models/mlp_resnet.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentMLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(StudentMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 256)  # New hidden layer\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(256, num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)  # Flatten the input for MLP\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kld_loss(student_logits, teacher_logits, temperature):\n",
    "    # KLDivLoss expects input to be in log-space\n",
    "    teacher_log_probs = nn.functional.log_softmax(\n",
    "        teacher_logits / temperature, dim=1)\n",
    "    student_probs = nn.functional.softmax(student_logits / temperature, dim=1)\n",
    "    return nn.KLDivLoss(reduction='batchmean')(teacher_log_probs, student_probs) * (temperature ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_student(teacher_model, supervision_loss=False, temperature=5.0, epochs=10):\n",
    "    student_model = StudentMLP(input_size=224*224*3,\n",
    "                               num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    top1_accuracies = []\n",
    "    top5_accuracies = []\n",
    "\n",
    "    optimizer = optim.Adam(student_model.parameters(),\n",
    "                           lr=0.00005, weight_decay=1e-4)\n",
    "    teacher_model.eval()  # Teacher model is fixed\n",
    "    student_model.train()\n",
    "    cse = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Get teacher logits\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher_model(images)\n",
    "\n",
    "            # Get student logits\n",
    "            student_logits = student_model(images)\n",
    "\n",
    "            # Compute distillation loss\n",
    "            loss1 = kld_loss(\n",
    "                student_logits, teacher_logits, temperature)\n",
    "\n",
    "            if supervision_loss:\n",
    "                loss = loss1 + cse(student_logits, labels)\n",
    "            else:\n",
    "                loss = loss1\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_value = loss.item()\n",
    "            running_loss += loss_value\n",
    "\n",
    "        top1_accuracy, top5_accuracy, _ = test(student_model)\n",
    "        top1_accuracies.append(top1_accuracy)\n",
    "        top5_accuracies.append(top5_accuracy)\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        # Store average loss for this epoch\n",
    "        train_losses.append(epoch_loss)\n",
    "        if epoch % 5 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}] Top-1: {top1_accuracy:.2f}%, Top-5: {top5_accuracy:.2f}%')\n",
    "\n",
    "    print('Finished distillation')\n",
    "    plot_metrics(train_losses, top1_accuracies, top5_accuracies)\n",
    "    return student_model\n",
    "\n",
    "\n",
    "if DISTILL_RESNET:\n",
    "    mlp_resnet = train_student(\n",
    "        resnet_classifier, supervision_loss=True, temperature=TEMPERATURE, epochs=NUM_EPOCHS)\n",
    "    torch.save(mlp_resnet.state_dict(), mlp_resnet_model_path)\n",
    "else:\n",
    "    mlp_resnet = StudentMLP(input_size=224*224*3,\n",
    "                            num_classes=NUM_CLASSES).to(device)\n",
    "    mlp_resnet.load_state_dict(\n",
    "        torch.load(mlp_resnet_model_path, weights_only=True))\n",
    "\n",
    "top1_accuracy, top5_accuracy, f1 = test(mlp_resnet)\n",
    "print(f\"Top-1: {top1_accuracy:.2f}%, Top-5: {top5_accuracy:.2f}%, F1: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
